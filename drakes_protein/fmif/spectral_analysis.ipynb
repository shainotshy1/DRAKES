{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ede35660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import GPT2LMHeadModel\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "from tree_spex import lgboost_fit, lgboost_to_fourier, lgboost_tree_to_fourier, ExactSolver # type:ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2545f53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "gpu_idx = 0\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu', gpu_idx)\n",
    "tokenizer = AutoTokenizer.from_pretrained('nferruz/ProtGPT2')\n",
    "model = GPT2LMHeadModel.from_pretrained('nferruz/ProtGPT2').to(device) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7ce46932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def protgpt_wrapper(samples, model, tokenizer):\n",
    "    res = []\n",
    "    for seq in samples:\n",
    "        out = tokenizer(seq, return_tensors=\"pt\")\n",
    "        input_ids = out.input_ids.cuda(device=model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, labels=input_ids)\n",
    "\n",
    "        ppl = (outputs.loss * input_ids.shape[1]).item()\n",
    "        res.append(ppl)\n",
    "    \n",
    "    res = np.array(res)\n",
    "    return res\n",
    "\n",
    "def calc_mask_reward(seq, mask):\n",
    "    tokens = list(seq)\n",
    "    for j in range(mask.shape[0]):\n",
    "        if mask[j] == 1:\n",
    "            tokens[j] = 'X'\n",
    "    mask_seq = \"\".join(tokens)\n",
    "    reward = protgpt_wrapper([mask_seq], model, tokenizer)\n",
    "    return reward\n",
    "\n",
    "def analyze_seq(seq, num_masks=500, p=0.5, top_interactions=25):\n",
    "    num_tokens = len(seq)\n",
    "    all_masks = np.random.choice(2, size=(num_masks, num_tokens), p = np.array([1-p, p]))\n",
    "\n",
    "    rewards = np.array([calc_mask_reward(seq, m) for m in all_masks]).ravel()\n",
    "\n",
    "    feature_names = [f\"x{i}\" for i in range(num_tokens)]\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    X_df = pd.DataFrame(all_masks, columns=feature_names)\n",
    "\n",
    "    best_model, cv_r2 = lgboost_fit(X_df, rewards)\n",
    "    print(f'CV r2: {cv_r2}')\n",
    "\n",
    "    # Algorithm: select top parent and its children\n",
    "    fourier_dict = lgboost_to_fourier(best_model)\n",
    "    fourier_dict_trunc = dict(sorted(fourier_dict.items(), key=lambda item: item[1], reverse=True)[:top_interactions])\n",
    "\n",
    "    target_features = set()\n",
    "    fourier_iter = iter(fourier_dict_trunc)\n",
    "\n",
    "    top_coefficient = next(fourier_iter, None)\n",
    "    if top_coefficient is None:\n",
    "        print(\"No meaningful interactions found\")\n",
    "        return\n",
    "    top_features = set()\n",
    "    if sum(top_coefficient) == 0: # type: ignore\n",
    "        top_coefficient = next(fourier_iter, None)\n",
    "        if top_coefficient is None:\n",
    "            print(\"No meaningful interactions found\")\n",
    "            return\n",
    "\n",
    "    nonzero_pos, = np.where(np.array(top_coefficient) == 1)\n",
    "    top_features.update(nonzero_pos)\n",
    "    target_features.update(nonzero_pos)\n",
    "\n",
    "    for k in fourier_dict_trunc:\n",
    "        if fourier_dict_trunc[k] <= 0: break # no more contributing coefficients left\n",
    "        nonzero_pos, = np.where(np.array(k) == 1)\n",
    "        if len(target_features & set(nonzero_pos)) > 0:\n",
    "            target_features.update(nonzero_pos)\n",
    "        descr = \"(\"\n",
    "        for i in range(len(nonzero_pos) - 1):\n",
    "            descr += f\"{nonzero_pos[i]}, \"\n",
    "        if len(nonzero_pos) > 0: descr += str(nonzero_pos[-1])\n",
    "        descr += \")\"                    \n",
    "        print(descr, fourier_dict_trunc[k])\n",
    "    print(f\"SPECTRAL targets: {sorted(list(target_features))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4ecacd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 1,  3,  5,  7,  9, 14, 18, 19, 20, 22, 23, 25, 27, 32, 34, 38, 47,\n",
      "       50]),)\n"
     ]
    }
   ],
   "source": [
    "# Structure: r6_560_TrROS_Hall\n",
    "\n",
    "seq1 = \"AVPAPVVTVLVAVTNPDGKVVLKRVTLSGLPRELKPGDKVTLPETGQEATIVEVLP\"\n",
    "seq2 = \"APPPPRVRVVVAVTRPDGRTELVTVELTGLPRPLRPGDTVTLPETGQKATVVEVLP\"\n",
    "diff_pos = np.where(np.array(list(seq1)) != np.array(list(seq2)))\n",
    "print(diff_pos)\n",
    "\n",
    "reward1, reward2 = protgpt_wrapper([seq1, seq2], model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a7abf62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward 1: 147.87730407714844\n",
      "Reward 2: 130.5386199951172\n"
     ]
    }
   ],
   "source": [
    "print(\"Reward 1:\", reward1)\n",
    "print(\"Reward 2:\", reward2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fa63c3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV r2: 0.47047575571636563\n",
      "() 147.9111299747269\n",
      "(31) 1.0844565421061554\n",
      "(0) 0.9811677968194322\n",
      "(14) 0.9570326399791297\n",
      "(21) 0.7194319694136097\n",
      "(23) 0.6554349626852427\n",
      "(46) 0.5598891939967457\n",
      "(12) 0.4897228231537926\n",
      "(18) 0.46777505095499883\n",
      "(13) 0.45707358829896627\n",
      "SPECTRAL targets: [31]\n"
     ]
    }
   ],
   "source": [
    "analyze_seq(seq1, num_masks=500, p=0.25, top_interactions=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2ef462a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV r2: 0.4812200030625572\n",
      "() 145.01779040351684\n",
      "(47) 1.5206155727991773\n",
      "(0) 0.9261279739756545\n",
      "(43) 0.9166225113008971\n",
      "(19) 0.72583083639104\n",
      "(21) 0.7224110147689785\n",
      "(46) 0.7101205746900472\n",
      "(9) 0.5912795634302482\n",
      "(10) 0.5626561106433193\n",
      "(27) 0.5153143672236693\n",
      "SPECTRAL targets: [47]\n"
     ]
    }
   ],
   "source": [
    "analyze_seq(seq2, num_masks=500, p=0.25, top_interactions=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0d07a54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 1,  3,  5,  7,  9, 14, 18, 19, 20, 22, 23, 25, 27, 32, 34, 38, 47,\n",
      "       50]),)\n"
     ]
    }
   ],
   "source": [
    "print(diff_pos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
